{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Funciones\n",
    "\n",
    "Notebook en el que he reunido todas las funciones creadas por mi misma para ayudarme en la extración de datos en el proceso de web scraping y análisis y limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las librerias\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones usadas en el primer Notebook( EDA_Extraccion_A.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para introducir nulos en listas\n",
    "def introducir_nulos(lista, posiciones):\n",
    "    '''\n",
    "    Lista hace referencia a la lista a la que queremos añadir valores nulos\n",
    "    posiciones lo introducimos como una tupla, con 1 ó varios valores según la necesidad\n",
    "    '''\n",
    "    for indice, posicion in enumerate(posiciones):\n",
    "        lista.insert(posicion, None)\n",
    "    print(lista)\n",
    "\n",
    "# Función para generar listas completas de Nulos\n",
    "def crear_lista_none(n):\n",
    "    '''\n",
    "    Crea una lista de n elementos, todos con el valor None.\n",
    "    '''\n",
    "    return [None] * n\n",
    "\n",
    "# Función para poder agrupar los valores ya que originalmente en la página vienen de 3 en tres\n",
    "def agrupar_de_tres(lista): \n",
    "    '''\n",
    "    Agrupa los elementos de una lista en sublistas de tamaño 3.\n",
    "\n",
    "    Args:\n",
    "    lista: La lista original.\n",
    "\n",
    "    Returns:\n",
    "    Una nueva lista que contiene sublistas de tamaño 3.\n",
    "    '''\n",
    "    return [lista[i:i+3] for i in range(0, len(lista), 3)]  \n",
    "\n",
    "# Función para automatizar la conexion y la comprobación del estado de la misma\n",
    "def accesibilidad (url):\n",
    "    conexion = requests.get(url)\n",
    "    print(conexion.status_code, conexion.reason)  \n",
    "\n",
    "# Función para extaer los nombres de los coches \n",
    "def lista_coches (url, tag, class_):\n",
    "    '''\n",
    "    Debemos obtener los tag y atributos que necesitamos de la página web (y se pasa en modo str)\n",
    "    '''\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs(conexion.text, \"lxml\")\n",
    "    coches = sopa.find_all( tag, class_) # no consigo que me coja la tupla con los tags\n",
    "    lista_coches = []\n",
    "    for indice, coche in enumerate(coches):\n",
    "        lista_coches.append(coche.text.strip())\n",
    "        indice += 1\n",
    "    return lista_coches \n",
    "\n",
    "# Función para extaer cosas a favor\n",
    "def lo_mejor (url, tag, class_):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    lista_a_favor = []\n",
    "    cosas_a_favor= sopa.find_all(tag, class_) \n",
    "    for indice, a_favor in enumerate(cosas_a_favor):\n",
    "        lista_a_favor.append(a_favor.text.strip()) \n",
    "    return lista_a_favor    \n",
    "\n",
    "# Función para las cosas en contra\n",
    "def lo_peor (url, tag, class_):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    lista_en_contra = []\n",
    "    cosas_en_contra= sopa.find_all(tag, class_) \n",
    "    for indice, en_contra in enumerate(cosas_en_contra):\n",
    "        lista_en_contra.append(en_contra.text.strip()) \n",
    "    return lista_en_contra\n",
    "\n",
    "# Función para sacar el texto que argumenta las opiniones\n",
    "def opiniones (url, tag, class_):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    lista_opiniones = []\n",
    "    opiniciones= sopa.find_all(tag, class_)\n",
    "    for indice, opinion in enumerate(opiniciones):\n",
    "        lista_opiniones.append(opinion.text.strip())\n",
    "        indice += 1\n",
    "    return lista_opiniones\n",
    "\n",
    "# Funcion para obtener la valoración\n",
    "def valoraciones(url, tag, class_):\n",
    "    # defino dos variables (tag y atributo) por si tengo que poner más de uno. A veces solo necesito poner un tag, por lo que a atributo le doy por defecto None, para que no me de problemas)\n",
    "    conexion = requests.get(url)\n",
    "    sopa= bs(conexion.text, \"lxml\")\n",
    "    lista_valoraciones = []\n",
    "    valoraciones= sopa.find_all(tag, class_)\n",
    "    for indice, valoracion in enumerate(valoraciones):\n",
    "        lista_valoraciones.append(valoracion.text.strip())\n",
    "        indice +=1\n",
    "    return lista_valoraciones\n",
    "\n",
    "# Función para sacar el texto que argumenta las opiniones\n",
    "def opiniones (url, tag, class_):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    lista_opiniones = []\n",
    "    opiniciones= sopa.find_all(tag, class_)\n",
    "    for indice, opinion in enumerate(opiniciones):\n",
    "        lista_opiniones.append(opinion.text.strip())\n",
    "        indice += 1\n",
    "    return lista_opiniones\n",
    "\n",
    " # Funcion para obtener todos los párrafos que me interesan de una lista y agruparlos en una lista nueva\n",
    "def agregar_un_parrafo(lista, posicion):\n",
    "    lista_parrafos= []\n",
    "    parrafo = lista[posicion]\n",
    "    lista_parrafos.append(parrafo)\n",
    "    return lista_parrafos\n",
    "\n",
    "# Creo una función para sacar precios\n",
    "def lista_precios (url, tag, class_):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    precios= sopa.find_all(tag, class_)\n",
    "    lista_precios = []\n",
    "    for indice, precio in enumerate(precios):\n",
    "        lista_precios.append(precio.text.strip())\n",
    "        indice += 1\n",
    "    return lista_precios\n",
    "\n",
    "# Función para las características\n",
    "def caracteristicas (url, tag, class_):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    caracteristicas= sopa.find_all(tag, class_)\n",
    "    lista_caracteristicas = []\n",
    "    for indice, caracteristica in enumerate(caracteristicas):\n",
    "        lista_caracteristicas.append(caracteristica.text.strip())\n",
    "        indice += 1\n",
    "    return lista_caracteristicas\n",
    "\n",
    "# Función para extraer las etiquetas\n",
    "def lista_etiquetas (url):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    etiquetado = sopa.find_all(\"img\", {\"alt\": True})\n",
    "# Creo la lista de las etiquetas\n",
    "    nombre_pegatinas = []\n",
    "    for nombre in etiquetado:\n",
    "        pegatina = nombre[\"alt\"] # recojo los nombres de las pegatinas con la primera letra de cada palabra en mayúscula ( para normaizar ya datos)\n",
    "        nombre_pegatinas.append(pegatina)\n",
    "        etiqueta = [x for x in nombre_pegatinas if \"Etiqueta ambiental \" in x] # de la lista me quedo con las que se llaman Etiqueta medioambiental\n",
    "        lista_etiquetas = []\n",
    "        lista_etiquetas.append(etiqueta)\n",
    "    return lista_etiquetas\n",
    "\n",
    "# Función para agregar dos párrafos\n",
    "def agregar_dos_parrafos (lista, posicion_1, posicion_2):\n",
    "    lista_agrupada =[]\n",
    "    parrafo_A = lista[posicion_1] \n",
    "    parrafo_B = lista[posicion_2]\n",
    "    parrafo = [parrafo_A + parrafo_B]\n",
    "    lista_agrupada.append(parrafo)\n",
    "    return lista_agrupada\n",
    "\n",
    "# Función para agregar tres párrafos\n",
    "def agregar_tres_parrafos (lista, posicion_1, posicion_2, posicion_3):\n",
    "    lista_agrupada = []\n",
    "    parrafo_A = lista[posicion_1] \n",
    "    parrafo_B = lista[posicion_2]\n",
    "    parrafo_C = lista[posicion_3]\n",
    "    parrafo = [parrafo_A + parrafo_B + parrafo_C]\n",
    "    lista_agrupada.append(parrafo)\n",
    "    return lista_agrupada\n",
    "\n",
    "# Función para poder agrupar los valores de 4 en 4\n",
    "def agrupar_de_cuatro(lista): \n",
    "    '''\n",
    "    Agrupa los elementos de una lista en sublistas de tamaño 4\n",
    "    Args:\n",
    "    lista: La lista original.\n",
    "    Returns:\n",
    "    Una nueva lista que contiene sublistas de tamaño 4.\n",
    "    '''\n",
    "    return [lista[i:i+4] for i in range(0, len(lista), 4)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones usadas en el tercer Notebook (DF_comparativo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo diferentes funciones para automatizar el proceso\n",
    "# Funciones adicionales\n",
    "# Función para comprobar la accesibilidad\n",
    "def accesibilidad (url):\n",
    "    conexion = requests.get(url)\n",
    "    print(conexion.status_code, conexion.reason)\n",
    "\n",
    "# Función para extraer datos de características\n",
    "def extraccion (url):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs(conexion.text, \"lxml\")\n",
    "    datos = sopa.find_all( 'span', class_=\"text-11\") \n",
    "    lista_datos = []\n",
    "    for indice, dato in enumerate(datos):\n",
    "        lista_datos.append(dato.text.strip())\n",
    "        indice += 1\n",
    "    return lista_datos\n",
    "\n",
    "# Función para extraer características 2\n",
    "def extraccion_2 (url):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs(conexion.text, \"lxml\")\n",
    "    datos = sopa.find_all( 'dd', class_=\"font-bold whitespace-nowrap lg:text-17 xl:text-18\") \n",
    "    lista_datos = []\n",
    "    for indice, dato in enumerate(datos):\n",
    "        lista_datos.append(dato.text.strip())\n",
    "        indice += 1\n",
    "    return lista_datos\n",
    "\n",
    "# Función para extraer las etiquetas\n",
    "def lista_etiquetas (url):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    etiquetado = sopa.find_all(\"img\", {\"alt\": True})\n",
    "# Creo la lista de las etiquetas\n",
    "    nombre_pegatinas = []\n",
    "    for nombre in etiquetado:\n",
    "        pegatina = nombre[\"alt\"] # recojo los nombres de las pegatinas con la primera letra de cada palabra en mayúscula ( para normaizar ya datos)\n",
    "        nombre_pegatinas.append(pegatina)\n",
    "        etiqueta = [x for x in nombre_pegatinas if \"Etiqueta medioambiental \" in x] # de la lista me quedo con las que se llaman Etiqueta medioambiental\n",
    "        lista_etiquetas = list(set(etiqueta)) # me quedo solo con los valores únicos\n",
    "    return lista_etiquetas\n",
    "\n",
    "# Función para extraer el tipo de motor \n",
    "def lista_motores (url):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    motores = sopa.find_all('td', None)\n",
    "# Creo la lista de los motores\n",
    "    lista_motores = []\n",
    "    for nombre in motores:\n",
    "        lista_motores.append(nombre.text)\n",
    "        motor_convencional = [x for x in lista_motores if \"MHEV\" in x] # de la lista me quedo con las que se llaman HEV\n",
    "        motor_diesel = [x for x in lista_motores if \"Diesel\" in x] \n",
    "        motor_gasolina = [x for x in lista_motores if \"Gasolina\" in x] \n",
    "        motor_glp = [x for x in lista_motores if \"LPG\" in x] \n",
    "        motor_combinado = [x for x in lista_motores if \"GLP\" in x] \n",
    "        motor_bifuel = [x for x in lista_motores if \"Bifuel\" in x]\n",
    "        motor_hibrido = [x for x in lista_motores if \"PHEV\" in x] # me quedo con los que tienen PHEV\n",
    "        motor_electrico = [x for x in lista_motores if \"BEV\" in x] # me quedo con los que tiene BEV\n",
    "        lista_completa = motor_convencional + motor_hibrido + motor_electrico + motor_diesel + motor_gasolina + motor_combinado + motor_glp + motor_bifuel\n",
    "        listado_motores = list(set(lista_completa)) # me quedo solo con los valores únicos\n",
    "    return listado_motores\n",
    "\n",
    "# Función para extraer el tipo de conbustible (gasolina, diesel, glp, bifuel, eéctrico e híbrido)\n",
    "def lista_combustibles (url):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    combustibles = sopa.find_all('td', None)\n",
    "# Creo la lista de los motores\n",
    "    lista_combustibles = []\n",
    "    for nombre in combustibles:\n",
    "        lista_combustibles.append(nombre.text)\n",
    "        combustible_diesel = [x for x in lista_combustibles if \"Diesel\" in x] \n",
    "        combustible_gasolina = [x for x in lista_combustibles if \"Gasolina\" in x] \n",
    "        combustible_combinado = [x for x in lista_combustibles if \"GLP\" in x] \n",
    "        combustible_bifuel = [x for x in lista_combustibles if \"Bifuel\" in x]\n",
    "        combustible_hibrido = [x for x in lista_combustibles if \"Híbrido\" in x] # me quedo con los que tienen PHEV\n",
    "        combustible_electrico = [x for x in lista_combustibles if \"Eléctrico\" in x] # me quedo con los que tiene BEV\n",
    "        lista_completa = combustible_diesel + combustible_gasolina + combustible_combinado + combustible_bifuel + combustible_hibrido + combustible_electrico\n",
    "        listado_combustible = list(set(lista_completa)) # me quedo solo con los valores únicos\n",
    "    return listado_combustible\n",
    "\n",
    "# Función para extraer lo peor\n",
    "def lo_peor (url):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs (conexion.text, 'lxml')\n",
    "    peores = sopa.find_all('div', class_=\"text-gray-dark text-16 sm:text-17 leading-5\", limit=2)\n",
    "    if peores != []: # por si no hay dato\n",
    "        lista_mejorable = []\n",
    "        for indice, peor in enumerate(peores):\n",
    "            lista_mejorable.append(peor.text.strip())\n",
    "            indice += 1\n",
    "            mejorable = [lista_mejorable[i] for i in range(1, len(lista_mejorable), 2)] # me quedo con la segunda que corresponde con lo mejorable\n",
    "    else:\n",
    "        mejorable = None\n",
    "    return mejorable\n",
    "\n",
    "# Función principal para la extraccion de todos los datos\n",
    "def datos (url, isofix):\n",
    "    conexion = requests.get(url)\n",
    "    sopa = bs(conexion.text, \"lxml\")\n",
    "    marcas = []\n",
    "    marca = sopa.find_all('a', class_=\"text-gray-dark font-bold\")\n",
    "    marcas.append(marca[1].text.strip())\n",
    "    modelos =[]\n",
    "    modelo = sopa.find('h1', class_=\"order-2 lg:order-1 leading-none lg:leading-[0.85] text-gray-800 flex-1 font-bold text-18 lg:text-48\")\n",
    "    modelos.append(((modelo.text.strip()).split())[2:]) # cogo la tercera palabra para quedare con el modelo\n",
    "    lista_datos = extraccion(url)\n",
    "    carrocerias = []\n",
    "    carroceria = lista_datos[0]\n",
    "    carrocerias.append(carroceria)\n",
    "    largos = []\n",
    "    largo = lista_datos[1]\n",
    "    largos.append(largo)\n",
    "    altos = []\n",
    "    alto = lista_datos[2]\n",
    "    altos.append(alto)\n",
    "    otros_datos = extraccion_2(url)\n",
    "    anchos = []\n",
    "    ancho = otros_datos[2]\n",
    "    anchos.append(ancho)\n",
    "    pesos = []\n",
    "    peso = otros_datos[3]\n",
    "    pesos.append(peso)\n",
    "    maleteros = []\n",
    "    maletero = otros_datos[5]\n",
    "    maleteros.append(maletero)\n",
    "    depositos = []\n",
    "    deposito = otros_datos[4]\n",
    "    depositos.append(deposito)\n",
    "    potencias = []\n",
    "    potencia = lista_datos[4]\n",
    "    potencias.append(potencia)\n",
    "    plazas = []\n",
    "    plaza = lista_datos[5]\n",
    "    plazas.append(plaza)\n",
    "    isofixes =[]\n",
    "    isofixes.append(isofix)\n",
    "    consumos = []\n",
    "    consumo = lista_datos[6]\n",
    "    consumos.append(consumo)\n",
    "    combustibles = []\n",
    "    combustible = lista_combustibles(url) \n",
    "    combustibles.append(combustible)\n",
    "    motores = []\n",
    "    motor  = lista_motores(url)\n",
    "    motores.append(motor)\n",
    "    emisiones = []\n",
    "    emision = lista_datos[7]\n",
    "    emisiones.append(emision)\n",
    "    etiquetas = []\n",
    "    etiqueta = lista_etiquetas(url)\n",
    "    etiquetas.append(etiqueta)\n",
    "    precios = []\n",
    "    precio = sopa.find('a', class_=\"text-primary text-22 font-bold leading-none\")\n",
    "    precios.append(precio.text.strip())\n",
    "    valoraciones = []\n",
    "    valoracion = sopa.find('div', class_=\"shrink text-center text-42 xl:text-48 font-bold\")\n",
    "    valoraciones.append(valoracion.text.strip())\n",
    "    lo_mejor = []\n",
    "    mejor = sopa.find('div', class_=\"text-gray-dark text-16 sm:text-17 leading-5\") # al poner solo el find me da el primer valor, que corresponde con lo mejor\n",
    "    if mejor != None: # por si no hay\n",
    "        lo_mejor.append(mejor.text.strip())\n",
    "    else:\n",
    "        lo_mejor.append(None)\n",
    "    lo_mejorable = []\n",
    "    peor = lo_peor(url)\n",
    "    lo_mejorable.append(peor)\n",
    "    opiniones = []\n",
    "    opinion = sopa.find('p', class_=\"font-bold pr-4 pt-4\")\n",
    "    if opinion != None: # por si no hay\n",
    "        opiniones.append(opinion.text.strip())\n",
    "    else:\n",
    "        opiniones.append(None)\n",
    "    return marcas, modelos, carrocerias, largos, altos, anchos, pesos, maleteros, depositos, potencias, plazas, isofixes, consumos, motores, emisiones, etiquetas, precios, valoraciones, lo_mejor, lo_mejorable, opiniones, combustibles\n",
    "\n",
    "# Función para introducir los datos en el diccionario\n",
    "def diccionario (lista):\n",
    "    lista_marcas.extend(lista[0])\n",
    "    lista_modelos.extend(lista[1])\n",
    "    lista_carrocerias.extend(lista[2])\n",
    "    lista_largos.extend(lista[3])\n",
    "    lista_altos.extend(lista[4])\n",
    "    lista_anchos.extend(lista[5])\n",
    "    lista_pesos.extend(lista[6])\n",
    "    lista_maleteros.extend(lista[7])\n",
    "    lista_depositos.extend(lista[8])\n",
    "    lista_potencias.extend(lista[9])\n",
    "    lista_plazas.extend(lista[10])\n",
    "    lista_isofixes.extend(lista[11])\n",
    "    lista_consumos.extend(lista[12])\n",
    "    listado_combustible.extend(lista[21])\n",
    "    listado_motores.extend(lista[13])\n",
    "    lista_emisiones.extend(lista[14])\n",
    "    listado_etiquetas.extend(lista[15])\n",
    "    lista_precios.extend(lista[16])\n",
    "    lista_valoraciones.extend(lista[17])\n",
    "    lista_lo_mejor.extend(lista[18])\n",
    "    lista_lo_mejorable.extend(lista[19])\n",
    "    lista_opiniones.extend(lista[20])\n",
    "    return lista_marcas, lista_modelos, lista_carrocerias,lista_largos, lista_altos,lista_anchos,lista_pesos,lista_maleteros,lista_depositos,lista_potencias,lista_plazas,lista_isofixes,lista_consumos,listado_motores, lista_emisiones,listado_etiquetas,lista_precios,lista_valoraciones,lista_lo_mejor,lista_lo_mejorable,lista_opiniones\n",
    "\n",
    "# Uno todas las funciones en un único paso\n",
    "def genera_datos (url,isofix):\n",
    "    accesibilidad(url)\n",
    "    data = datos(url, isofix)\n",
    "    diccionario(data)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
